{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import tweepy\n",
    "from textblob import TextBlob\n",
    "import json\n",
    "import os\n",
    "import pandas as p \n",
    "\n",
    "class TwitterClient(object):\n",
    " '''\n",
    "    Generic Twitter Class for sentiment analysis.\n",
    "'''\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    '''\n",
    "    Utility function to clean tweet text by removing links, special characters\n",
    "    using simple regex statements.\n",
    "    '''\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tweet_sentiment(tweet):\n",
    "    '''\n",
    "    Utility function to classify sentiment of passed tweet\n",
    "    using textblob's sentiment method\n",
    "    '''\n",
    "    # create TextBlob object of passed tweet text\n",
    "    analysis = TextBlob(tweet)\n",
    "    # set sentiment\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tweets(filename):\n",
    "    '''\n",
    "    Main function to fetch tweets and parse just the text part.\n",
    "    '''\n",
    "    import json\n",
    "\n",
    "    tweets={}\n",
    "    f = open(filename)\n",
    "    data = json.load(f)\n",
    "    \n",
    "    labeled = []\n",
    "    for tweet in data:\n",
    "         tweets = {'text': tweet[\"text\"], 'sentiment': get_tweet_sentiment(tweet[\"text\"])}\n",
    "         labeled.append(tweets)\n",
    "    return labeled\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11-07-2017\n",
      "NA 0\n",
      "KS 0\n",
      "UT 0\n",
      "OR 1\n",
      "DC 0\n",
      "OK 0\n",
      "NM 0\n",
      "LA 0\n",
      "WA 0\n",
      "NY 1\n",
      "MS 0\n",
      "PR 0\n",
      "WY 0\n",
      "VT 0\n",
      "DE 0\n",
      "MT 0\n",
      "KY 0\n",
      "VA 1\n",
      "TX 4\n",
      "MA 0\n",
      "IL 0\n",
      "AZ 0\n",
      "PA 1\n",
      "CO 0\n",
      "IA 0\n",
      "NJ 0\n",
      "SD -1\n",
      "MO 1\n",
      "WI 0\n",
      "GA 0\n",
      "IN 0\n",
      "NE 0\n",
      "AL 0\n",
      "CT 0\n",
      "ND 0\n",
      "GU 0\n",
      "HI 0\n",
      "CA 3\n",
      "MN 1\n",
      "TN 0\n",
      "NH 0\n",
      "MI 1\n",
      "VI 0\n",
      "NV 1\n",
      "NC 1\n",
      "AS 0\n",
      "ME 0\n",
      "ID 0\n",
      "WV 0\n",
      "MP 0\n",
      "OH 0\n",
      "FL -1\n",
      "SC 0\n",
      "AR 0\n",
      "MD -1\n",
      "AK 0\n",
      "RI 1\n",
      "\n",
      "\n",
      "11-06-2017\n",
      "NA 0\n",
      "KS 1\n",
      "UT 1\n",
      "OR 0\n",
      "DC 0\n",
      "OK 0\n",
      "NM 0\n",
      "LA 0\n",
      "WA 0\n",
      "NY 1\n",
      "MS 0\n",
      "PR 0\n",
      "WY 0\n",
      "VT 0\n",
      "DE 0\n",
      "MT 0\n",
      "KY 3\n",
      "VA 0\n",
      "TX 2\n",
      "MA 1\n",
      "IL 0\n",
      "AZ 0\n",
      "PA 0\n",
      "CO 0\n",
      "IA 1\n",
      "NJ 0\n",
      "SD 0\n",
      "MO 0\n",
      "WI 1\n",
      "GA 0\n",
      "IN 0\n",
      "NE 0\n",
      "AL 0\n",
      "CT 0\n",
      "ND 0\n",
      "GU 0\n",
      "HI 0\n",
      "CA -2\n",
      "MN 0\n",
      "TN 0\n",
      "NH 0\n",
      "MI 0\n",
      "VI 0\n",
      "NV 0\n",
      "NC 1\n",
      "AS 0\n",
      "ME 0\n",
      "ID 0\n",
      "WV 0\n",
      "MP 0\n",
      "OH 0\n",
      "FL 0\n",
      "SC 0\n",
      "AR 0\n",
      "MD 0\n",
      "AK 0\n",
      "RI 0\n",
      "\n",
      "\n",
      "11-08-2017\n",
      "NA 0\n",
      "KS 0\n",
      "UT 0\n",
      "OR 1\n",
      "DC 0\n",
      "OK 1\n",
      "NM 0\n",
      "LA 2\n",
      "WA 0\n",
      "NY 5\n",
      "MS 1\n",
      "PR 0\n",
      "WY 0\n",
      "VT 0\n",
      "DE 0\n",
      "MT 0\n",
      "KY 0\n",
      "VA 1\n",
      "TX 3\n",
      "MA 0\n",
      "IL 0\n",
      "AZ 4\n",
      "PA 0\n",
      "CO 1\n",
      "IA 0\n",
      "NJ 1\n",
      "SD 0\n",
      "MO 1\n",
      "WI 0\n",
      "GA -1\n",
      "IN 0\n",
      "NE 0\n",
      "AL 0\n",
      "CT 0\n",
      "ND 0\n",
      "GU 0\n",
      "HI 0\n",
      "CA 9\n",
      "MN 0\n",
      "TN 0\n",
      "NH 0\n",
      "MI 2\n",
      "VI 0\n",
      "NV 0\n",
      "NC 2\n",
      "AS 0\n",
      "ME 0\n",
      "ID -1\n",
      "WV 0\n",
      "MP 0\n",
      "OH 0\n",
      "FL 2\n",
      "SC 0\n",
      "AR 0\n",
      "MD 2\n",
      "AK 0\n",
      "RI 0\n",
      "\n",
      "\n",
      "12-05-2017\n",
      "NA 0\n",
      "KS 0\n",
      "UT 0\n",
      "OR 0\n",
      "DC 0\n",
      "OK 0\n",
      "NM 0\n",
      "LA 0\n",
      "WA 0\n",
      "NY 0\n",
      "MS 0\n",
      "PR 0\n",
      "WY 0\n",
      "VT 0\n",
      "DE 0\n",
      "MT 0\n",
      "KY 0\n",
      "VA 0\n",
      "TX 0\n",
      "MA 0\n",
      "IL 0\n",
      "AZ 0\n",
      "PA 0\n",
      "CO 0\n",
      "IA 0\n",
      "NJ 0\n",
      "SD 0\n",
      "MO 0\n",
      "WI 0\n",
      "GA 0\n",
      "IN 0\n",
      "NE 0\n",
      "AL 0\n",
      "CT 0\n",
      "ND 0\n",
      "GU 0\n",
      "HI 0\n",
      "CA 0\n",
      "MN 0\n",
      "TN 0\n",
      "NH 0\n",
      "MI 1\n",
      "VI 0\n",
      "NV 0\n",
      "NC 0\n",
      "AS 0\n",
      "ME 0\n",
      "ID 0\n",
      "WV 0\n",
      "MP 0\n",
      "OH 0\n",
      "FL 0\n",
      "SC 0\n",
      "AR 0\n",
      "MD 0\n",
      "AK 0\n",
      "RI 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    \n",
    "    #directory of tweets, organized by date, then state \n",
    "    indir = '/Users/crystal/Big-Data-proj/filtered_tweets'\n",
    "    \n",
    "    #iterating through the each directory to look at the tweets in each state\n",
    "    for filename in os.listdir(indir):\n",
    "        \n",
    "        if filename != \".DS_Store\":\n",
    "            print(\"{}\".format(filename))\n",
    "            for file in os.listdir(\"filtered_tweets/\"+filename+\"/\"):\n",
    "                state_change = {}\n",
    "                \n",
    "                \n",
    "                if file.endswith(\".json\"):\n",
    "                    ptweet = []\n",
    "                    ntweet = []\n",
    "                    netweet = []\n",
    "                    tweet = get_tweets(\"filtered_tweets/\"+filename+\"/\"+file)\n",
    "\n",
    "                    \n",
    "                    # sorting tweets by positive, negative and neutral sentiment \n",
    "                    for t in tweet:\n",
    "\n",
    "                        if t['sentiment'] == 'positive':\n",
    "                            ptweet.append(t)\n",
    "\n",
    "\n",
    "\n",
    "                        elif t['sentiment'] == 'negative':\n",
    "                            ntweet.append(t)\n",
    "\n",
    "                        elif t['sentiment'] == 'neutral':\n",
    "                            netweet.append(t)\n",
    "\n",
    "\n",
    "                    \n",
    "                    # check to make sure there are tweets in file\n",
    "                    if(len(tweet) > 0):\n",
    "                        \n",
    "                        #find net sentiment \n",
    "                        net_daily = len(ptweet) - len(ntweet)\n",
    "                        state_change[file[0:2]] = net_daily\n",
    "                        \n",
    "                        \n",
    "                        # picking negative tweets from tweets\n",
    "                        ntweet = [tweet for tweet in tweet if tweet['sentiment'] == 'negative']\n",
    "                        \n",
    "                    #no tweets in file\n",
    "                    else:\n",
    "                        state_change[file[0:2]] = 0\n",
    "    \n",
    "                        \n",
    "                changeData = p.Series(state_change)\n",
    "                for name, val in changeData.iteritems():\n",
    "                    print(name,val)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    # calling main function\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
